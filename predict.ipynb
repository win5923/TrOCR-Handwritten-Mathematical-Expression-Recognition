{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_path = './data2/2014/18_em_4.bmp'  #'./data2/2014/18_em_1.bmp'   './data2/train/2_em_7.bmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIEAAABXCAIAAACspbE1AAACL0lEQVR4nO3cW3OEIAyGYez0//9le+GM3dElBEgg4vtctna75uPkMSUAAAAAAADg3zb7C4yz7/vlJ9sWYvdDfAlv9+qfIsTwO/sLeBHqLm88PpX5rcCcXP2jxOc227Z93X5kEj/D/tMY8rCjr2xVN+q0zljU1pxH1jpnnQwuhOrn6n4ZpoZZbSw6NIzmExdIC2YgV1PfzId1iAUzaDD3KGHZ+UApwjHaq/tBhADSSv1AU9C5x8M562Tg4cisLa3PQ3F5SzIo2/e94WhDL0p/zNHsYe0oVPwr21XpU/uB99pcrsv5W4M2rmgfQTNwpR/fc2dVez7z7hkZfO7hpSi1O++9fYPo84EV/SoFb+TVKDQXs3AwroV+IUEMJ8tCNKzkSCIZrouUlxIjXDuMxuu8ae4COg3/zj6D4u0LwmL/nWwyoJQ9Rh8nk9ad8VhUez2d6SGNvJZJD8gxGIs0xe080bY29/mA5l/kmMH0+5mfonc+yN2pQAB69v2A6tcyyyB30zLVL/JdmxKAhuVYFPMutvhefb9pEGYZ0Ama0Q/mc7l+YP6Zaxt63hRfWWZAAG26MmAeNtGeASdErbQco1F9W9X9gADMafsBpffTPh9UvQYFAlUGdAJX1XMybd9c3VhEAB5U/cC79C9/UGnyM4HMNIn7TSMYl0Gx+u8ciNKwDHhEUNC788KNpMHfrhuHcQap9H4Bqn9nfy2TAGqZFUV+aSgEjs8nU30AAAAAAIAH+gOcfMbI5w1/mQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=129x87 at 0x7FAE3CA32310>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e ^ { - n }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_name = img_path.strip(\".bmp\")\n",
    "img_name = img_name.partition(\"2014/\")\n",
    "\n",
    "with open('./data2/2014/caption.txt') as label:\n",
    "    for line in label.readlines():\n",
    "        #print(line.split(\"\\t\"))\n",
    "        if img_name[2] == line.split(\"\\t\")[0]:\n",
    "            print(line.split(\"\\t\")[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\") #'microsoft/trocr-base-handwritten'\n",
    "model = VisionEncoderDecoderModel.from_pretrained('./checkpoint_eval_2014_small_stage1/checkpoint-12000')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 384, 384])\n"
     ]
    }
   ],
   "source": [
    "pixel_values = processor(img, return_tensors=\"pt\").pixel_values\n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "greedy search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ^ { - m }\n"
     ]
    }
   ],
   "source": [
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ^ { - m }\n",
      "e ^ { - m }\n",
      "2 ^ { - n }\n",
      "e ^ { - n }\n",
      "e ^ { - r }\n"
     ]
    }
   ],
   "source": [
    "beam_output = model.generate(\n",
    "    pixel_values, \n",
    "    num_beams=10, \n",
    "    early_stopping=True,\n",
    "    num_return_sequences=5\n",
    ")\n",
    "print(processor.batch_decode(beam_output, skip_special_tokens=True)[0])\n",
    "print(processor.batch_decode(beam_output, skip_special_tokens=True)[1])\n",
    "print(processor.batch_decode(beam_output, skip_special_tokens=True)[2])\n",
    "print(processor.batch_decode(beam_output, skip_special_tokens=True)[3])\n",
    "print(processor.batch_decode(beam_output, skip_special_tokens=True)[4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/data/TrOCR/predict.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B203.64.95.124/root/data/TrOCR/predict.ipynb#ch0000011vscode-remote?line=0'>1</a>\u001b[0m sample_output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B203.64.95.124/root/data/TrOCR/predict.ipynb#ch0000011vscode-remote?line=1'>2</a>\u001b[0m     pixel_values, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B203.64.95.124/root/data/TrOCR/predict.ipynb#ch0000011vscode-remote?line=2'>3</a>\u001b[0m     do_sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B203.64.95.124/root/data/TrOCR/predict.ipynb#ch0000011vscode-remote?line=3'>4</a>\u001b[0m     top_k\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B203.64.95.124/root/data/TrOCR/predict.ipynb#ch0000011vscode-remote?line=4'>5</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B203.64.95.124/root/data/TrOCR/predict.ipynb#ch0000011vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(processor\u001b[39m.\u001b[39mbatch_decode(sample_output, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py?line=27'>28</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:1290\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1281'>1282</a>\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1282'>1283</a>\u001b[0m         input_ids,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1283'>1284</a>\u001b[0m         expand_size\u001b[39m=\u001b[39mnum_beams \u001b[39m*\u001b[39m num_return_sequences,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1284'>1285</a>\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1285'>1286</a>\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1286'>1287</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1288'>1289</a>\u001b[0m     \u001b[39m# 13. run beam sample\u001b[39;00m\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1289'>1290</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeam_sample(\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1290'>1291</a>\u001b[0m         input_ids,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1291'>1292</a>\u001b[0m         beam_scorer,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1292'>1293</a>\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1293'>1294</a>\u001b[0m         logits_warper\u001b[39m=\u001b[39;49mlogits_warper,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1294'>1295</a>\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1295'>1296</a>\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1296'>1297</a>\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1297'>1298</a>\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1298'>1299</a>\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1299'>1300</a>\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1300'>1301</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1301'>1302</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1303'>1304</a>\u001b[0m \u001b[39melif\u001b[39;00m is_group_beam_gen_mode:\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1304'>1305</a>\u001b[0m     \u001b[39mif\u001b[39;00m num_return_sequences \u001b[39m>\u001b[39m num_beams:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:2398\u001b[0m, in \u001b[0;36mGenerationMixin.beam_sample\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=2393'>2394</a>\u001b[0m next_token_scores \u001b[39m=\u001b[39m next_token_scores\u001b[39m.\u001b[39mview(batch_size, num_beams \u001b[39m*\u001b[39m vocab_size)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=2395'>2396</a>\u001b[0m probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(next_token_scores, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=2397'>2398</a>\u001b[0m next_tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmultinomial(probs, num_samples\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m num_beams)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=2398'>2399</a>\u001b[0m next_token_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mgather(next_token_scores, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, next_tokens)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=2400'>2401</a>\u001b[0m next_token_scores, _indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msort(next_token_scores, descending\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sample_output = model.generate(\n",
    "    pixel_values, \n",
    "    do_sample=True, \n",
    "    top_k=50\n",
    ")\n",
    "print(processor.batch_decode(sample_output, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def ocr_image(src_img):  #greedy\n",
    "#  pixel_values = processor(images=src_img, return_tensors=\"pt\").pixel_values\n",
    "#  generated_ids = model.generate(pixel_values)\n",
    "#  return processor.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def ocr_image2(src_img):  #beam search\n",
    "#  pixel_values = processor(images=src_img, return_tensors=\"pt\").pixel_values\n",
    "#  generated_ids = model.generate(pixel_values, num_beams=5,early_stopping=True)\n",
    "#  return processor.batch_decode(generated_ids, skip_special_tokens=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s><s>\\\\sqrt { 4. 8 }</s>'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ocr_image(img)\n",
    "\n",
    "#ocr_image2(img)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
