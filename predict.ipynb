{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_path = './data2/2014/18_em_1.bmp'  #'./data2/2014/18_em_1.bmp'   './data2/train/2_em_7.bmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABFCAIAAADGjl8gAAAB+klEQVR4nO2a247DIAxEw2r//5fZh0gRGxLAF3yJ5ry2De4wxjbtcQAAAAAAAAAAAPko3gGsUms1XrGUiTi/NnEsYi+QBE/tcinV45azPOGmeWRJrJw9CSXQAH/tsijV8+MdQGJ8fDc+7K5Xg1vSwXfZy+uFtXY34YI7a4ypdp9x3IlbnX1zXCJ9feps6lS9sPMd1VC9vuz6+7a0cAv9e+N9THer1iqRzyhn268xCFfxsFt8lGTFb/ruUZF2z9o3sN1nod2i6VrYqdSr9vioUorc49tz1rLnIK0lr/WmPUqo1iS67xjZaoNKNuAOir+pS7WCZx/qpzadjOdj34qDaX8Xed4spViOyZycrbWqVzTSA4Ps35J2g/3cgXAtUrRUH7QQfEf6SuyABqtINC3/ub3Ki5aWs7ex5kIlFEUYt9OMmHV6lMHC9m3dinBvBiRBnmenk6DNXchbA0R1nGSw5dwFDGIdvHPA7VaDEdLjZ3dbXm2uOOOOM4QZrK55B7WpRDzafCyNzbZJtdOddULdF0xR8J38HjGXZBc6513SL3/Izhm1WtHK5y7lyqQlmcZONGuFu2Q33n7E0TqgP/U7WX/y9j2TYjMQyylTFnuUdYES/LatjnyecZhnszAeHFWO5mQ5e0T6R23WnI0AtOMD7QAAAAAAAAAAZOQPQa3/ea5/hVoAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=105x69 at 0x7FDB702B5700>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\sqrt { 4 8 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_name = img_path.strip(\".bmp\")\n",
    "img_name = img_name.partition(\"2014/\")\n",
    "\n",
    "with open('./data2/2014/caption.txt') as label:\n",
    "    for line in label.readlines():\n",
    "        #print(line.split(\"\\t\"))\n",
    "        if img_name[2] == line.split(\"\\t\")[0]:\n",
    "            print(line.split(\"\\t\")[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\") #'microsoft/trocr-base-handwritten'\n",
    "model = VisionEncoderDecoderModel.from_pretrained('./checkpoint_eval_2014_small_stage1_num_beams=10/checkpoint-12000')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 384, 384])\n"
     ]
    }
   ],
   "source": [
    "pixel_values = processor(img, return_tensors=\"pt\").pixel_values\n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "greedy search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\sqrt { 4. 8 }\n"
     ]
    }
   ],
   "source": [
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\sqrt { 4. 8 }\n",
      "\\sqrt { 4. 8 }\n",
      "\\sqrt { 4. 8 }\n",
      "\\sqrt { 4. 8 }\n",
      "\\sqrt { 4. 8 }\n"
     ]
    }
   ],
   "source": [
    "beam_output = model.generate(\n",
    "    pixel_values, \n",
    "    num_beams=10, \n",
    "    early_stopping=True,\n",
    "    num_return_sequences=5,\n",
    "    max_length = 490\n",
    "    #no_repeat_ngram_size = 3\n",
    ")\n",
    "print(processor.batch_decode(beam_output, skip_special_tokens=True)[0])\n",
    "print(processor.batch_decode(beam_output, skip_special_tokens=True)[1])\n",
    "print(processor.batch_decode(beam_output, skip_special_tokens=True)[2])\n",
    "print(processor.batch_decode(beam_output, skip_special_tokens=True)[3])\n",
    "print(processor.batch_decode(beam_output, skip_special_tokens=True)[4])\n",
    "\n",
    "\n",
    "#max_length = 預測的字數\n",
    "#no_repeat_ngram_size = 0(無窮大) 不出現重複的字幾次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/data/TrOCR/predict.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B203.64.95.124/root/data/TrOCR/predict.ipynb#ch0000011vscode-remote?line=0'>1</a>\u001b[0m sample_output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B203.64.95.124/root/data/TrOCR/predict.ipynb#ch0000011vscode-remote?line=1'>2</a>\u001b[0m     pixel_values, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B203.64.95.124/root/data/TrOCR/predict.ipynb#ch0000011vscode-remote?line=2'>3</a>\u001b[0m     do_sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B203.64.95.124/root/data/TrOCR/predict.ipynb#ch0000011vscode-remote?line=3'>4</a>\u001b[0m     top_k\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B203.64.95.124/root/data/TrOCR/predict.ipynb#ch0000011vscode-remote?line=4'>5</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B203.64.95.124/root/data/TrOCR/predict.ipynb#ch0000011vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(processor\u001b[39m.\u001b[39mbatch_decode(sample_output, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py?line=27'>28</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:1290\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1281'>1282</a>\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1282'>1283</a>\u001b[0m         input_ids,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1283'>1284</a>\u001b[0m         expand_size\u001b[39m=\u001b[39mnum_beams \u001b[39m*\u001b[39m num_return_sequences,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1284'>1285</a>\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1285'>1286</a>\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1286'>1287</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1288'>1289</a>\u001b[0m     \u001b[39m# 13. run beam sample\u001b[39;00m\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1289'>1290</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeam_sample(\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1290'>1291</a>\u001b[0m         input_ids,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1291'>1292</a>\u001b[0m         beam_scorer,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1292'>1293</a>\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1293'>1294</a>\u001b[0m         logits_warper\u001b[39m=\u001b[39;49mlogits_warper,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1294'>1295</a>\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1295'>1296</a>\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1296'>1297</a>\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1297'>1298</a>\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1298'>1299</a>\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1299'>1300</a>\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1300'>1301</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1301'>1302</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1303'>1304</a>\u001b[0m \u001b[39melif\u001b[39;00m is_group_beam_gen_mode:\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1304'>1305</a>\u001b[0m     \u001b[39mif\u001b[39;00m num_return_sequences \u001b[39m>\u001b[39m num_beams:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:2398\u001b[0m, in \u001b[0;36mGenerationMixin.beam_sample\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=2393'>2394</a>\u001b[0m next_token_scores \u001b[39m=\u001b[39m next_token_scores\u001b[39m.\u001b[39mview(batch_size, num_beams \u001b[39m*\u001b[39m vocab_size)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=2395'>2396</a>\u001b[0m probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(next_token_scores, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=2397'>2398</a>\u001b[0m next_tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmultinomial(probs, num_samples\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m num_beams)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=2398'>2399</a>\u001b[0m next_token_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mgather(next_token_scores, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, next_tokens)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=2400'>2401</a>\u001b[0m next_token_scores, _indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msort(next_token_scores, descending\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sample_output = model.generate(\n",
    "    pixel_values, \n",
    "    do_sample=True, \n",
    "    top_k=50\n",
    ")\n",
    "print(processor.batch_decode(sample_output, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def ocr_image(src_img):  #greedy\n",
    "#  pixel_values = processor(images=src_img, return_tensors=\"pt\").pixel_values\n",
    "#  generated_ids = model.generate(pixel_values)\n",
    "#  return processor.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def ocr_image2(src_img):  #beam search\n",
    "#  pixel_values = processor(images=src_img, return_tensors=\"pt\").pixel_values\n",
    "#  generated_ids = model.generate(pixel_values, num_beams=5,early_stopping=True)\n",
    "#  return processor.batch_decode(generated_ids, skip_special_tokens=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s><s>\\\\sqrt { 4. 8 }</s>'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ocr_image(img)\n",
    "\n",
    "#ocr_image2(img)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
